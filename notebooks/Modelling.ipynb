{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\jdrel\\OneDrive\\Documents\\Data_Science\\Springboard\\Capstone-2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/interim/Small_df.csv')\n",
    "\n",
    "clusters = pd.read_csv('./data/interim/Cluster_features.csv')['K=8']\n",
    "\n",
    "dc = pd.concat([data, clusters], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dc.drop(['Unnamed: 0', 'labels'], axis = 1)\n",
    "y = np.where(dc['labels'] == 'normal.', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "XnoC = data.drop(['labels', 'Unnamed: 0'], axis = 1)\n",
    "xnoctrain,xnoctest,ytrain,y_test = train_test_split(XnoC, y, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True #type: ignore\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Using CPU instead.\n",
      "Backend engine: tensorflow\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print(f'Default GPU Device: {tf.test.gpu_device_name()}')\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU instead.\")\n",
    "\n",
    "# Print backend engine and available devices\n",
    "print('Backend engine:', K.backend())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = Sequential()\n",
    "\n",
    "nnet.add(Dense(13, activation = 'relu', input_dim = X.shape[1]))\n",
    "nnet.add(Dense(8, activation = 'relu'))\n",
    "nnet.add(Dense(1, activation = 'relu'))\n",
    "\n",
    "nnet.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "nnet.fit(xnoctrain.astype('float32'), y_train.astype('float32'), epochs = 10, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0363 - binary_accuracy: 0.9884\n",
      "Epoch 2/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0101 - binary_accuracy: 0.9971\n",
      "Epoch 3/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0095 - binary_accuracy: 0.9972\n",
      "3860/3860 [==============================] - 4s 904us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     24285\n",
      "           1       1.00      1.00      1.00     99220\n",
      "\n",
      "    accuracy                           1.00    123505\n",
      "   macro avg       0.99      1.00      0.99    123505\n",
      "weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nnet = Sequential()\n",
    "\n",
    "nnet.add(Dense(8, activation = 'relu', input_dim = X.shape[1]))\n",
    "nnet.add(Dense(5, activation = 'relu'))\n",
    "nnet.add(Dense(3, activation = 'relu'))\n",
    "nnet.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nnet.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "nnet.fit(X_train.astype('float32'), y_train.astype('float32'), epochs = 3, batch_size = 50)\n",
    "\n",
    "preds = nnet.predict(X_test)\n",
    "\n",
    "preds = np.where(preds < .5, 0, 1)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860/3860 [==============================] - 3s 866us/step\n"
     ]
    }
   ],
   "source": [
    "preds = nnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.20      0.20     24425\n",
      "           1       0.80      0.80      0.80     99080\n",
      "\n",
      "    accuracy                           0.68    123505\n",
      "   macro avg       0.50      0.50      0.50    123505\n",
      "weighted avg       0.68      0.68      0.68    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.where(preds < .5, 0, 1)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smurf.              0.568378\n",
       "neptune.            0.216997\n",
       "normal.             0.196909\n",
       "back.               0.004459\n",
       "satan.              0.003216\n",
       "ipsweep.            0.002524\n",
       "portsweep.          0.002105\n",
       "warezclient.        0.002065\n",
       "teardrop.           0.001982\n",
       "pod.                0.000534\n",
       "nmap.               0.000468\n",
       "guess_passwd.       0.000107\n",
       "buffer_overflow.    0.000061\n",
       "land.               0.000043\n",
       "warezmaster.        0.000040\n",
       "imap.               0.000024\n",
       "rootkit.            0.000020\n",
       "loadmodule.         0.000018\n",
       "ftp_write.          0.000016\n",
       "multihop.           0.000014\n",
       "phf.                0.000008\n",
       "perl.               0.000006\n",
       "spy.                0.000004\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Small Data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Big Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forrest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
