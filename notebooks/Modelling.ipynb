{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\jdrel\\OneDrive\\Documents\\Data_Science\\Springboard\\Capstone-2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/interim/Small_df.csv')\n",
    "\n",
    "clusters = pd.read_csv('./data/interim/Cluster_features.csv')['K=8']\n",
    "\n",
    "dc = pd.concat([data, clusters], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dc.drop(['Unnamed: 0', 'labels'], axis = 1)\n",
    "y = np.where(dc['labels'] == 'normal.', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "XnoC = data.drop(['labels', 'Unnamed: 0'], axis = 1)\n",
    "xnoctrain,xnoctest,ytrain,ytest = train_test_split(XnoC, y, test_size= 0.25, random_state = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True #type: ignore\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Using CPU instead.\n",
      "Backend engine: tensorflow\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print(f'Default GPU Device: {tf.test.gpu_device_name()}')\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU instead.\")\n",
    "\n",
    "# Print backend engine and available devices\n",
    "print('Backend engine:', K.backend())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0360 - binary_accuracy: 0.9914\n",
      "Epoch 2/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0132 - binary_accuracy: 0.9954\n",
      "Epoch 3/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0124 - binary_accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6142e1090>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnetnoc = Sequential()\n",
    "\n",
    "nnetnoc.add(Dense(8, activation = 'relu', input_dim = XnoC.shape[1]))\n",
    "nnetnoc.add(Dense(5, activation = 'relu'))\n",
    "nnetnoc.add(Dense(3, activation = 'relu'))\n",
    "nnetnoc.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nnetnoc.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "nnetnoc.fit(xnoctrain.astype('float32'), ytrain.astype('float32'), epochs = 3, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860/3860 [==============================] - 3s 890us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     24387\n",
      "           1       1.00      1.00      1.00     99118\n",
      "\n",
      "    accuracy                           1.00    123505\n",
      "   macro avg       1.00      0.99      0.99    123505\n",
      "weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predsnoc = nnetnoc.predict(xnoctest)\n",
    "\n",
    "predsnoc = np.where(predsnoc < .5, 0, 1)\n",
    "print(classification_report(ytest, predsnoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.1439 - binary_accuracy: 0.9886\n",
      "Epoch 2/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0174 - binary_accuracy: 0.9957\n",
      "Epoch 3/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0115 - binary_accuracy: 0.9968\n",
      "3860/3860 [==============================] - 4s 902us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     24285\n",
      "           1       1.00      1.00      1.00     99220\n",
      "\n",
      "    accuracy                           1.00    123505\n",
      "   macro avg       1.00      0.99      0.99    123505\n",
      "weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nnet = Sequential()\n",
    "\n",
    "nnet.add(Dense(8, activation = 'relu', input_dim = X.shape[1]))\n",
    "nnet.add(Dense(5, activation = 'relu'))\n",
    "nnet.add(Dense(3, activation = 'relu'))\n",
    "nnet.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nnet.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "nnet.fit(X_train.astype('float32'), y_train.astype('float32'), epochs = 3, batch_size = 50)\n",
    "\n",
    "preds = nnet.predict(X_test)\n",
    "\n",
    "preds = np.where(preds < .5, 0, 1)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860/3860 [==============================] - 3s 862us/step\n"
     ]
    }
   ],
   "source": [
    "preds = nnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     24285\n",
      "           1       1.00      1.00      1.00     99220\n",
      "\n",
      "    accuracy                           1.00    123505\n",
      "   macro avg       0.99      0.99      0.99    123505\n",
      "weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.where(preds < .5, 0, 1)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smurf.              0.568378\n",
       "neptune.            0.216997\n",
       "normal.             0.196909\n",
       "back.               0.004459\n",
       "satan.              0.003216\n",
       "ipsweep.            0.002524\n",
       "portsweep.          0.002105\n",
       "warezclient.        0.002065\n",
       "teardrop.           0.001982\n",
       "pod.                0.000534\n",
       "nmap.               0.000468\n",
       "guess_passwd.       0.000107\n",
       "buffer_overflow.    0.000061\n",
       "land.               0.000043\n",
       "warezmaster.        0.000040\n",
       "imap.               0.000024\n",
       "rootkit.            0.000020\n",
       "loadmodule.         0.000018\n",
       "ftp_write.          0.000016\n",
       "multihop.           0.000014\n",
       "phf.                0.000008\n",
       "perl.               0.000006\n",
       "spy.                0.000004\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, data['labels'], test_size=.25, random_state = 42)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_train = to_categorical(y_train, num_classes = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0512 - accuracy: 0.9900\n",
      "Epoch 2/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0147 - accuracy: 0.9963\n",
      "Epoch 3/3\n",
      "7411/7411 [==============================] - 9s 1ms/step - loss: 0.0133 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6145bd450>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = Sequential()\n",
    "\n",
    "nnet.add(Dense(38, activation = 'relu', input_dim = X.shape[1]))\n",
    "nnet.add(Dense(31, activation = 'relu'))\n",
    "nnet.add(Dense(23, activation = 'softmax'))\n",
    "\n",
    "nnet.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "nnet.fit(X_train, y_train, epochs = 3, batch_size = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdrel\\miniconda3\\envs\\Capstone-2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jdrel\\miniconda3\\envs\\Capstone-2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           back.       0.98      0.99      0.99       540\n",
      "buffer_overflow.       0.00      0.00      0.00        11\n",
      "      ftp_write.       0.00      0.00      0.00         2\n",
      "   guess_passwd.       0.88      0.78      0.82         9\n",
      "           imap.       0.00      0.00      0.00         3\n",
      "        ipsweep.       0.85      0.92      0.88       325\n",
      "           land.       0.80      0.80      0.80         5\n",
      "     loadmodule.       0.00      0.00      0.00         1\n",
      "       multihop.       0.00      0.00      0.00         2\n",
      "        neptune.       1.00      1.00      1.00     26666\n",
      "           nmap.       0.50      0.02      0.04        50\n",
      "         normal.       0.99      1.00      0.99     24285\n",
      "           perl.       0.00      0.00      0.00         1\n",
      "            phf.       0.00      0.00      0.00         2\n",
      "            pod.       1.00      0.96      0.98        50\n",
      "      portsweep.       0.88      0.97      0.92       278\n",
      "        rootkit.       0.00      0.00      0.00         2\n",
      "          satan.       1.00      0.85      0.92       391\n",
      "          smurf.       1.00      1.00      1.00     70382\n",
      "       teardrop.       1.00      1.00      1.00       223\n",
      "    warezclient.       0.90      0.57      0.70       271\n",
      "    warezmaster.       0.00      0.00      0.00         6\n",
      "\n",
      "        accuracy                           1.00    123505\n",
      "       macro avg       0.54      0.49      0.50    123505\n",
      "    weighted avg       1.00      1.00      1.00    123505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdrel\\miniconda3\\envs\\Capstone-2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#preds = nnet.predict(X_test)\n",
    "pred = preds.argmax(axis = 1)\n",
    "ints = label_encoder.classes_\n",
    "predictions = [ints[i] for i in pred]\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Small Data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Big Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forrest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
