{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to capstone 2\n",
    "os.chdir(r'C:\\Users\\jdrel\\OneDrive\\Documents\\Data_Science\\Springboard\\Capstone-2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the small training set\n",
    "small_train = pd.read_csv('./data/processed/small_train.csv')\n",
    "\n",
    "# Import the small test set\n",
    "small_test = pd.read_csv('./data/processed/small_test.csv')\n",
    "\n",
    "# Import the small training set\n",
    "big_train = pd.read_csv('./data/processed/big_train.csv')\n",
    "\n",
    "# Import the small test set\n",
    "big_test = pd.read_csv('./data/processed/big_test.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have loaded the datasets, I need to separate out the features (X) from the target variable (y) so that it is easy to run the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X which is only features in the training data\n",
    "X_small = small_train.drop(['labels', 'group'], axis = 1)\n",
    "# Create X small for the test set\n",
    "X_small_test = small_test.drop(['labels', 'group'], axis = 1)\n",
    "# Do the same thing for the bigger data set\n",
    "X_big = big_train.drop(['labels', 'group'], axis = 1)\n",
    "# Create X big for the test set\n",
    "X_big_test = big_test.drop(['labels'], axis = 1)\n",
    "# Create the binary y for the training set.\n",
    "y_train = np.where(small_train['labels'] == 'normal.', 0, 1)\n",
    "# Create the binary y for the test set\n",
    "y_test = np.where(small_test['labels'] == 'normal.', 0, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neural Network**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to use a gpu for my neural network to speed up the processing significantly. Unfortunately Tensorflow has discontinued support for windows so I will not be able to use my gpu. Fortunately the models that I used in this notebook are not too time intensive that I needed to use the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use the CPU\n",
    "    print(\"GPU is not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 228.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [3650001/3673822], Loss: 0.6146, Accuracy: 0.8966\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 264.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [3650001/3673822], Loss: 0.0640, Accuracy: 0.9965\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 283.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [3650001/3673822], Loss: 0.0138, Accuracy: 0.9967\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 294.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [3650001/3673822], Loss: 0.0103, Accuracy: 0.9968\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 286.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [3650001/3673822], Loss: 0.0091, Accuracy: 0.9977\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 270.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [3650001/3673822], Loss: 0.0086, Accuracy: 0.9979\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 283.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [3650001/3673822], Loss: 0.0073, Accuracy: 0.9982\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 316.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [3650001/3673822], Loss: 0.0071, Accuracy: 0.9980\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 283.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [3650001/3673822], Loss: 0.0077, Accuracy: 0.9979\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 283.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [3650001/3673822], Loss: 0.0067, Accuracy: 0.9983\r"
     ]
    }
   ],
   "source": [
    "# Create a train and test data from the full dataset\n",
    "X_train, X_test, y_tr, y_te = train_test_split(X_small, y_train, test_size = .25, random_state = 42)\n",
    "\n",
    "# Define the model class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 12)\n",
    "        self.fc2 = nn.Linear(12, 12)\n",
    "        self.fc3 = nn.Linear(12, 12)\n",
    "        self.fc4 = nn.Linear(12, 12)\n",
    "        self.fc5 = nn.Linear(12, 8)\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.activation(self.fc5(x))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = Net(X_train.shape[1])\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Convert the data to torch tensors and move to the GPU\n",
    "X_train_tensor = torch.Tensor(X_train.values).float().to(device)\n",
    "y_train_tensor = torch.Tensor(y_tr).float().to(device)\n",
    "X_test_tensor = torch.Tensor(X_test.values).float().to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "batch_size = 50000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the data at the start of each epoch\n",
    "    indices = np.random.permutation(len(X_train_tensor))\n",
    "    shuffled_X = X_train_tensor[indices]\n",
    "    shuffled_y = y_train_tensor[indices]\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Mini-batch training\n",
    "    for i in tqdm(range(0, len(X_train_tensor), batch_size), leave = True):\n",
    "\n",
    "        batch_X = shuffled_X[i:i+batch_size]\n",
    "        batch_y = shuffled_y[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        outputs = outputs.view(-1)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predicted_labels = (outputs > 0.5).float()\n",
    "        accuracy = (predicted_labels == batch_y).float().mean()\n",
    "\n",
    "    # Print loss and accuracy\n",
    "    print(f'\\rEpoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train_tensor)}], Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}', end = '\\r')\n",
    "        \n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model and data back to the CPU\n",
    "model.to(\"cpu\")\n",
    "X_test_tensor = X_test_tensor.to(\"cpu\")\n",
    "\n",
    "# Perform predictions on the test set\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_tensor)\n",
    "\n",
    "# Convert the predictions tensor to a numpy array\n",
    "preds = preds.numpy()\n",
    "\n",
    "# Classify the predicitions as 0 or 1 since the values the sigmoid produces are not exact\n",
    "preds = np.where(preds < .5, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    243103\n",
      "           1       1.00      1.00      1.00    981505\n",
      "\n",
      "    accuracy                           1.00   1224608\n",
      "   macro avg       0.99      1.00      0.99   1224608\n",
      "weighted avg       1.00      1.00      1.00   1224608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report \n",
    "print(classification_report(y_te, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Small Data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model that I'm going to run is going to use only the training data and using train_test_split to create the test set. Because the official test set contains new values, I want to see how well the data and the model perform when they are only using the type of data that they have been trained for. This in a sense is cross validation because I can still go back and change the model based on this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "74/74 [==============================] - 4s 10ms/step - loss: 0.5903 - binary_accuracy: 0.8316\n",
      "Epoch 2/3\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1657 - binary_accuracy: 0.9861\n",
      "Epoch 3/3\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0236 - binary_accuracy: 0.9968\n",
      "38269/38269 [==============================] - 39s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    243103\n",
      "           1       1.00      1.00      1.00    981505\n",
      "\n",
      "    accuracy                           1.00   1224608\n",
      "   macro avg       1.00      1.00      1.00   1224608\n",
      "weighted avg       1.00      1.00      1.00   1224608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and test data from the full dataset\n",
    "X_train, X_test, y_tr, y_te = train_test_split(X_small, y_train, test_size = .25, random_state = 42)\n",
    "\n",
    "# Initialize the model\n",
    "nnettrain = Sequential()\n",
    "\n",
    "# Create the first layer of the deep learning model with input set the number of features in X_train\n",
    "nnettrain.add(Dense(12, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettrain.add(Dense(12, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettrain.add(Dense(12, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettrain.add(Dense(12, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettrain.add(Dense(8, activation = 'relu'))\n",
    "# Finish on a single node with sigmoid activation so that the result is between 0 and 1\n",
    "nnettrain.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile the network with the standard optimiizer and loss function\n",
    "nnettrain.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "# Train the model whle converting X_train and y_train into floats. Given the accuracy 3 epochs is good enough\n",
    "nnettrain.fit(X_train.astype('float32'), y_tr.astype('float32'), epochs = 3, batch_size = 50000)\n",
    "\n",
    "# Create the predictions\n",
    "preds = nnettrain.predict(X_test)\n",
    "\n",
    "# Classify the predicitions as 0 or 1 since the values the sigmoid produces are not exact\n",
    "preds = np.where(preds < .5, 0, 1)\n",
    "# Print the classification report \n",
    "print(classification_report(y_te, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an incredible result. The model was able to perfectly predict if there was an intrusion in the test set every single time. This may in part be due to luck as some of the rarer intrusion types might not have been in the test set.\n",
    "\n",
    "With this result I'm now going to try and use this model on the test set to see if we can get the same results as cross validation with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9720/9720 [==============================] - 10s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78     60592\n",
      "           1       0.96      0.92      0.94    250436\n",
      "\n",
      "    accuracy                           0.91    311028\n",
      "   macro avg       0.84      0.89      0.86    311028\n",
      "weighted avg       0.92      0.91      0.91    311028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions for the test result\n",
    "preds_of = nnettrain.predict(X_small_test)\n",
    "\n",
    "# Classify the predicitions as 0 or 1 since the values the sigmoid produces are not exact\n",
    "preds_of = np.where(preds_of < .5, 0, 1)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, preds_of))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the model was significantly less than perfect with the official test set. This is in part because there are a lot of new intrusion types that the model couldn't train for. My theory is that the model found patterns that predicted the training intrusions but never found a generalizable pattern for normal observations. Once the intrusions changed the model struggled to keep up with the new information.\n",
    "\n",
    "It is also important to remember that there is an uneven distribution between intrusions and non intrusions. Below I calculated the percentage of the test set that had intrusions in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Intrusion: 19.5%\n",
      "Intrusion: 80.5%\n"
     ]
    }
   ],
   "source": [
    "# Store the unique values and their counts in separate variables\n",
    "vals, counts = np.unique(y_test, return_counts = True)\n",
    "# Create value_counts(normalize=True) for np array\n",
    "prop_counts = counts/len(y_test)\n",
    "# print the % of observations with no intrusion\n",
    "print(f'No Intrusion: {round(prop_counts[0]*100, 1)}%')\n",
    "# print the % of observations with an intrusion\n",
    "print(f'Intrusion: {round(prop_counts[1]*100,1)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that only 19.5% of the test set contains no intrusion so If I had built a model that always predicted intrusion, It would have been high on precision and recall for 1 and very low for zero. The accuracy scores show that this model is providing important value as they would be 50 if the model guessed intrusion every time. It is also important to note that the test set contains new intrusion types that aren't like the training set. Given the very high training scores, if I had a dataset that didn't have the new intrusion types this model would have been nearly perfect.\n",
    "\n",
    "To get a better understanding of how well the model performed at predicting normal observations I can use the Reciever under the Curve metric which measures the True Positive Rate (TPR) against the False Positive Rate (FPR). A ROC area of greater that 0.8 is good and an ROC curve of 0.9 or greater is excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the false positive rate, true positive rate, and threshold for normal observations\n",
    "fpr, tpr, thresholds = roc_curve(y_test, preds_of)\n",
    "\n",
    "# calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc);\n",
    "# Plot the baseline 50-50 dashed line\n",
    "plt.plot([0, 1], [0, 1], '--', color = 'w');\n",
    "# Set the x axis limits\n",
    "plt.xlim([0.0, 1.0]);\n",
    "# Set the y axis limits\n",
    "plt.ylim([0.0, 1.05]);\n",
    "# Label the x-axis\n",
    "plt.xlabel('False Positive Rate');\n",
    "# Label the y-axis\n",
    "plt.ylabel('True Positive Rate');\n",
    "# Title the plot\n",
    "plt.title('Receiver Operating Characteristic');\n",
    "# Create the legend that has the area under the curve\n",
    "plt.legend(loc=\"lower right\");\n",
    "# Show the graph\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ROC curve of .89 is really good although not great. Given the disparity between the official testset and the unofficial testset, it is important to see how the model did when the observations contained the new attack types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.13      0.24     18729\n",
      "\n",
      "    accuracy                           0.13     18729\n",
      "   macro avg       0.50      0.07      0.12     18729\n",
      "weighted avg       1.00      0.13      0.24     18729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all the new attack types. This list was taken from preprocessing notebook\n",
    "new_attacks = ['xsnoop.', 'udpstorm.', 'mscan.', 'named.', 'processtable.', 'xlock.', 'snmpgetattack.', \n",
    "               'snmpguess.', 'worm.', 'ps.', 'httptunnel.', 'sendmail.', 'saint.', 'mailbomb.', 'apache2.', 'xterm.', 'sqlattack.']\n",
    "# Create a mask for all values that are in new attacks in the test set\n",
    "mask = small_test['labels'].isin(new_attacks)\n",
    "# Use the mask to find all the y-test values that are from new labels\n",
    "y_test_new = y_test[mask]\n",
    "# Use the mask to find all the prediction values that are from new labels\n",
    "preds_new = preds_of[mask]\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_new, preds_new, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the result that I hoped for. Out of all the observations that had new attack types only 13% of the time the model classified those as attack types. We can see which attack types the model was best at predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apache2.         793\n",
       "processtable.    694\n",
       "saint.           603\n",
       "mscan.           262\n",
       "httptunnel.      119\n",
       "ps.                7\n",
       "xterm.             5\n",
       "xlock.             4\n",
       "xsnoop.            4\n",
       "sendmail.          4\n",
       "sqlattack.         2\n",
       "named.             1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe that is a column of labels that only has the new labels\n",
    "new_labels = pd.DataFrame(small_test['labels'][mask], columns = ['labels']).reset_index(drop=True)\n",
    "# create a dataframe that is a column of labels that only has the predictions\n",
    "pred_df = pd.DataFrame(preds_new, columns = ['pred']).reset_index(drop=True)\n",
    "# Combine the labels and the predictions for analysis\n",
    "new_intrusions = pd.concat([new_labels, pred_df], axis = 1)\n",
    "# Run value counts when the prediction is positive to see which new intrusions the model captures\n",
    "new_intrusions.loc[new_intrusions['pred'] == 1, 'labels'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which new intrusion types the model was the worst at predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snmpgetattack.    7741\n",
       "mailbomb.         5000\n",
       "snmpguess.        2406\n",
       "mscan.             791\n",
       "saint.             133\n",
       "processtable.       65\n",
       "httptunnel.         39\n",
       "named.              16\n",
       "sendmail.           13\n",
       "ps.                  9\n",
       "xterm.               8\n",
       "xlock.               5\n",
       "udpstorm.            2\n",
       "worm.                2\n",
       "apache2.             1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run value counts when the prediction is negative to see which new intrusions the model doesn't capture\n",
    "new_intrusions.loc[new_intrusions['pred'] == 0, 'labels'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that some of the new intrusion types the model totally disregarded where as some of the new intrusion types it did a great job. If this model was operational it would most likely start doing significantly better after it had trained on the new attack types while still giving some protection against attack types that were similar to the training set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Categorical Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "73477/73477 [==============================] - 121s 2ms/step - loss: 0.0120 - accuracy: 0.9970\n",
      "Epoch 2/3\n",
      "73477/73477 [==============================] - 122s 2ms/step - loss: 0.0075 - accuracy: 0.9982\n",
      "Epoch 3/3\n",
      "73477/73477 [==============================] - 119s 2ms/step - loss: 0.0073 - accuracy: 0.9983\n",
      "38269/38269 [==============================] - 43s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " brute force       0.00      0.00      0.00        19\n",
      "       files       0.00      0.00      0.00         6\n",
      "    internal       1.00      1.00      1.00    702901\n",
      "        none       1.00      1.00      1.00    243103\n",
      "       pings       1.00      1.00      1.00    268035\n",
      "     scripts       0.00      0.00      0.00         3\n",
      "      sweeps       0.97      0.90      0.94     10285\n",
      "       warez       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           1.00   1224608\n",
      "   macro avg       0.50      0.49      0.49   1224608\n",
      "weighted avg       1.00      1.00      1.00   1224608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and test data from the full dataset\n",
    "X_train, X_test, y_tr, y_te = train_test_split(X_small, small_train['group'], test_size = .25, random_state = 42)\n",
    "\n",
    "# Encode the different groups as numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "# fit and transform the y training data with label encoder\n",
    "y_group = label_encoder.fit_transform(y_tr)\n",
    "# transfrom the encoded data to a categorical variable\n",
    "y_group = to_categorical(y_group, num_classes = 8)\n",
    "\n",
    "# Initialize the model\n",
    "nnettraincat = Sequential()\n",
    "\n",
    "# Create the first layer of the deep learning model with input set the number of features in X_train\n",
    "nnettraincat.add(Dense(12, activation = 'relu', input_dim = X_small.shape[1]))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettraincat.add(Dense(12, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettraincat.add(Dense(12, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettraincat.add(Dense(12, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnettraincat.add(Dense(12, activation = 'relu'))\n",
    "# Finish with the same amount of nodes as categories that there are to predict\n",
    "nnettraincat.add(Dense(8, activation = 'softmax'))\n",
    "\n",
    "# Compile the network with the standard optimiizer and loss function\n",
    "nnettraincat.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Train the model with X_train and the encoded categorical y_group\n",
    "nnettraincat.fit(X_train, y_group, epochs = 3, batch_size = 50)\n",
    "# Create the predictions. This creates an array that has as many columns as potential predictions\n",
    "preds = nnettraincat.predict(X_test)\n",
    "# Take the highest prediction as the model's prediction\n",
    "pred = preds.argmax(axis = 1)\n",
    "# get the intrusions corresponding to the encoder class.\n",
    "ints = label_encoder.classes_\n",
    "# Assign each of the predictions to the group that they correspond to\n",
    "predictions = [ints[i] for i in pred]\n",
    "# Print out the classification report\n",
    "print(classification_report(y_te, predictions, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This continues the earlier model's training perfect results for predicting if there is an intrusion or not. It is important to note that every group over with over 300 observations the model performed very well. Unfortunately the rare groups the model had a lot more trouble with. Given the amount of observations that are in the dataset the model is still clearly giving important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine y_group variable as the 'group' column from the test set\n",
    "y_group = small_test['group']\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# fit and transform y_group\n",
    "y_group = label_encoder.fit_transform(y_group)\n",
    "# Transform the y_group variable to a categorical variable\n",
    "y_group = to_categorical(y_group, num_classes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9720/9720 [==============================] - 10s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " brute force       0.00      0.00      0.00      7574\n",
      "       files       0.00      0.00      0.00         5\n",
      "    internal       0.96      0.99      0.98    165217\n",
      "        none       0.69      0.89      0.78     60592\n",
      "       pings       0.98      0.91      0.94     63109\n",
      "     scripts       0.00      0.00      0.00      8763\n",
      "      sweeps       0.55      0.50      0.52      4166\n",
      "       warez       0.00      0.00      0.00      1602\n",
      "\n",
      "    accuracy                           0.89    311028\n",
      "   macro avg       0.40      0.41      0.40    311028\n",
      "weighted avg       0.85      0.89      0.87    311028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the test dataset with the previous model\n",
    "preds = nnettraincat.predict(X_small_test)\n",
    "# Find the prediction that the model likes the most\n",
    "pred = preds.argmax(axis = 1)\n",
    "# Get the corresponding group types from label_encoder\n",
    "ints = label_encoder.classes_\n",
    "# find the intrusions for each prediction\n",
    "predictions = [ints[i] for i in pred]\n",
    "# Print the classification report\n",
    "print(classification_report(small_test['group'], predictions, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a horrible result as the none group had a significant reduction in precision. It is important to realize that the model was able to correctly identify 89% of the normal observations but there were a lot of false positives. I'm sure that there are a lot of ways to optimize the model that would better capture what is an intrusion and what is not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Big Data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the chance to use the bigger dataset that is supposed to contain every features that can help distinguish between the intrusion types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " brute force       0.00      0.00      0.00        19\n",
      "       files       0.00      0.00      0.00         3\n",
      "    internal       1.00      1.00      1.00    703507\n",
      "        none       1.00      1.00      1.00    242578\n",
      "       pings       1.00      1.00      1.00    267962\n",
      "     scripts       0.00      0.00      0.00         4\n",
      "      sweeps       0.99      0.98      0.98     10290\n",
      "       warez       0.00      0.00      0.00       245\n",
      "\n",
      "    accuracy                           1.00   1224608\n",
      "   macro avg       0.50      0.50      0.50   1224608\n",
      "weighted avg       1.00      1.00      1.00   1224608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and test data from the full dataset\n",
    "X_train, X_test, y_tr, y_te = train_test_split(X_big, small_train['group'], test_size = .25)\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# fit and transform the y training data with label encoder\n",
    "y_group = label_encoder.fit_transform(y_tr)\n",
    "# transfrom the encoded data to a categorical variable\n",
    "y_group = to_categorical(y_group, num_classes = 8)\n",
    "\n",
    "# Initialize the model\n",
    "nnetbigcat = Sequential()\n",
    "\n",
    "# Create the first layer of the deep learning model with input set the number of features in X_train\n",
    "nnetbigcat.add(Dense(61, activation = 'relu', input_dim = X_big.shape[1]))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(61, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(53, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(38, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(25, activation = 'relu'))\n",
    "# Add a middle layer to give the model more complexity\n",
    "nnetbigcat.add(Dense(14, activation = 'relu'))\n",
    "# Finish with the same amount of nodes as categories that there are to predict\n",
    "nnetbigcat.add(Dense(8, activation = 'softmax'))\n",
    "# Compile the network with the standard optimiizer and loss function\n",
    "nnetbigcat.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "# Train the model with X_train and the encoded categorical y_group\n",
    "nnetbigcat.fit(X_train.astype('float32'), y_group, epochs = 2, batch_size = 50)\n",
    "# Create the predictions. This creates an array that has as many columns as potential predictions\n",
    "preds = nnetbigcat.predict(X_test)\n",
    "# Take the highest prediction as the model's prediction\n",
    "pred = preds.argmax(axis = 1)\n",
    "# get the intrusions corresponding to the encoder class.\n",
    "ints = label_encoder.classes_\n",
    "# Assign each of the predictions to the group that they correspond to\n",
    "predictions = [ints[i] for i in pred]\n",
    "# Print out the classification report\n",
    "print(classification_report(y_te, predictions, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was slightly more precise than the previous model where the sweeps group was nearly perfect. Now lets see how it performs on the official test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9720/9720 [==============================] - 14s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " brute force       0.00      0.00      0.00      7574\n",
      "       files       0.00      0.00      0.00         5\n",
      "    internal       0.97      1.00      0.99    165217\n",
      "        none       0.71      0.92      0.80     60592\n",
      "       pings       0.98      0.92      0.95     63109\n",
      "     scripts       0.00      0.00      0.00      8763\n",
      "      sweeps       0.77      0.68      0.72      4166\n",
      "       warez       0.00      0.00      0.00      1602\n",
      "\n",
      "    accuracy                           0.91    311028\n",
      "   macro avg       0.43      0.44      0.43    311028\n",
      "weighted avg       0.87      0.91      0.88    311028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the test dataset with the previous model\n",
    "preds = nnetbigcat.predict(X_big_test)\n",
    "# Find the prediction that the model likes the most\n",
    "pred = preds.argmax(axis = 1)\n",
    "# Get the corresponding group types from label_encoder\n",
    "ints = label_encoder.classes_\n",
    "# find the intrusions for each prediction\n",
    "predictions = [ints[i] for i in pred]\n",
    "# Print the classification report\n",
    "print(classification_report(small_test['group'], predictions, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the neural networks were amazing at predicting intrusion types that had already happened. If this model was to be used at a security firm than the more diverse set of intrusions that it was allowed to train on the better it would do. Unfortunately there are a set of attacks that without training data is impossible for this model to catch. I don't know if there is a better way to train the model to catch them.\n",
    "\n",
    "The one thing that I wish I had done better was to get the model to generate more rare events. Given the size of the dataset and the rarety of some of the intrusion types the models just ignored those types and stuck with the more common intrusion types. If I had weighted the model and created some synthetic data with some of the rarer intrusion types that might have helped the model predict all intrusion types."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forrest**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second type of model that I will use is random forrest which is an ensemble method of decision trees. The idea is that since hacking is an inherently human act, the process should follow some sort of decision tree where certain features being elevated or lowered should lead to certain types of intrusions. I did not have enough time to conduct a grid search or random search so I just did the basic version of a Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77     60592\n",
      "           1       0.96      0.91      0.94    250436\n",
      "\n",
      "    accuracy                           0.90    311028\n",
      "   macro avg       0.83      0.89      0.85    311028\n",
      "weighted avg       0.91      0.90      0.90    311028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state= 42)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X_small, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "rf_pred = rf.predict(X_small_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, rf_pred, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly worse than the neural network but it is very close. It could be that If the hyper parameters were correctly tuned that the results would be better. Below is a categorical random forrest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state= 42)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X_small, y_group)\n",
    "\n",
    "# Predict the test set\n",
    "rf_pred_group = rf.predict(X_small_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " brute force       0.01      0.01      0.01      7574\n",
      "       files       0.00      0.00      0.00         5\n",
      "    internal       0.82      0.80      0.81    165217\n",
      "        none       0.54      0.99      0.70     60592\n",
      "       pings       0.94      0.28      0.43     63109\n",
      "     scripts       0.00      0.00      0.00      8763\n",
      "      sweeps       0.20      0.50      0.29      4166\n",
      "       warez       0.00      0.00      0.00      1602\n",
      "\n",
      "    accuracy                           0.68    311028\n",
      "   macro avg       0.31      0.32      0.28    311028\n",
      "weighted avg       0.74      0.68      0.66    311028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the test dataset with the previous model\n",
    "preds = rf.predict(X_small_test)\n",
    "# Find the prediction that the model likes the most\n",
    "pred = preds.argmax(axis = 1)\n",
    "# Get the corresponding group types from label_encoder\n",
    "ints = label_encoder.classes_\n",
    "# find the intrusions for each prediction\n",
    "predictions = [ints[i] for i in pred]\n",
    "# Print the classification report\n",
    "print(classification_report(small_test['group'], predictions, zero_division = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did significantly worse than the neural network. It is important to note that it recalled 99% of all the non intrusion observations but its precision was so low that has much less importance than the recall would indicate.\n",
    "\n",
    "Below is the same but with the bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " brute force       0.05      0.42      0.09      7574\n",
      "       files       0.00      0.00      0.00         5\n",
      "    internal       0.53      0.00      0.00    165217\n",
      "        none       0.21      0.78      0.34     60592\n",
      "       pings       0.98      0.28      0.43     63109\n",
      "     scripts       0.00      0.00      0.00      8763\n",
      "      sweeps       0.76      0.76      0.76      4166\n",
      "       warez       1.00      0.13      0.23      1602\n",
      "\n",
      "    accuracy                           0.23    311028\n",
      "   macro avg       0.44      0.30      0.23    311028\n",
      "weighted avg       0.54      0.23      0.17    311028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# fit and transform y_group\n",
    "y_group = label_encoder.fit_transform(small_train['group'])\n",
    "# Transform the y_group variable to a categorical variable\n",
    "y_group = to_categorical(y_group, num_classes = 8)\n",
    "\n",
    "\n",
    "# Create a random forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state= 42)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X_big, y_group)\n",
    "\n",
    "# Predict the test dataset with the previous model\n",
    "preds = rf.predict(X_big_test)\n",
    "# Find the prediction that the model likes the most\n",
    "pred = preds.argmax(axis = 1)\n",
    "# Get the corresponding group types from label_encoder\n",
    "ints = label_encoder.classes_\n",
    "# find the intrusions for each prediction\n",
    "predictions = [ints[i] for i in pred]\n",
    "# Print the classification report\n",
    "print(classification_report(small_test['group'], predictions, zero_division = 0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "From these results it is clear that the neural network model is the best model. With more time I could run a lot of hyper paramater tuning and investigate if taking the highest value soft max is the best decision or if maybe sometimes the model hints at something rarer that gets covered up by higher values of more common types. But until then the best model was the big data categorical model. It recalled 92% of all non intrusion observations and 71% precision while also giving valuable insight into the type of intrusion it was. This means that when the model predicted that there was an intrusion there was a 1-(.195*(1-.92)) = 98.4% chance that there was an intrusion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
